{"paragraphs":[{"text":"println(\"Spark version \" + sc.version)\nprintln(\"Scala version \" + util.Properties.versionString)\n","user":"anonymous","dateUpdated":"2018-01-11T10:04:46+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Spark version 2.1.0\nScala version version 2.11.8\n"}]},"apps":[],"jobName":"paragraph_1515509136856_-1480312812","id":"20180109-144536_1758966050","dateCreated":"2018-01-09T14:45:36+0000","dateStarted":"2018-01-11T10:04:47+0000","dateFinished":"2018-01-11T10:04:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16501"},{"text":"// Global variables\nval dir_data = \"data/dev-test-exploratory-analysis\"\nval fcomm_clean = dir_data + \"/224564804326967_facebook_comments_clean/part-*\"\n// End of Global variables","user":"anonymous","dateUpdated":"2018-01-11T10:04:47+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ndir_data: String = data/dev-test-exploratory-analysis\n\nfcomm_clean: String = data/dev-test-exploratory-analysis/224564804326967_facebook_comments_clean/part-*\n"}]},"apps":[],"jobName":"paragraph_1515524930889_-1995061310","id":"20180109-190850_2088089175","dateCreated":"2018-01-09T19:08:50+0000","dateStarted":"2018-01-11T10:04:47+0000","dateFinished":"2018-01-11T10:04:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16502"},{"text":"// Read text file\nval commentsDF = sc.textFile(fcomm_clean)\n                    .filter(_.nonEmpty)\n                   .filter(l => !l.contains(\"null\"))\n                   .filter(l => !l.contains(\"0\"))\n                   .filter(s => s.length > 1)","user":"anonymous","dateUpdated":"2018-01-11T10:04:47+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ncommentsDF: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1080] at filter at <console>:133\n"}]},"apps":[],"jobName":"paragraph_1515524987153_1173974174","id":"20180109-190947_443034625","dateCreated":"2018-01-09T19:09:47+0000","dateStarted":"2018-01-11T10:04:47+0000","dateFinished":"2018-01-11T10:04:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16503"},{"text":"// View data\ncommentsDF.take(7).map(s => println(s))","user":"anonymous","dateUpdated":"2018-01-11T10:04:47+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"byt zaujimavy cr kupovat vajicko 89 9 korunk d nevediet stat sk z sliepkama d d d byt kriz d d d\nnaozaj pomaly velmi pomaly zvysovanie cena mat rychly tempo\njulius holz zaujimavy byt fakt vajickovy kriz nekonat nemecky\nkonecna byt cas\njak kriz kriz sty urobit dotedy nekupit vajce kto nebyt povodny cena\nbuda asi ta ochutene holandsky slovensky asi nic nechovat treba vozit hnoj eu\nrychlo cena hora dol pomalicky taky slovensky vajce dostatok teraz vyzmykat clovek dat nenazranec\n\nres625: Array[Unit] = Array((), (), (), (), (), (), ())\n"}]},"apps":[],"jobName":"paragraph_1515525035761_-2022458392","id":"20180109-191035_847815263","dateCreated":"2018-01-09T19:10:35+0000","dateStarted":"2018-01-11T10:04:48+0000","dateFinished":"2018-01-11T10:04:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16504"},{"text":"import org.apache.spark.sql.functions.desc\n// Count words\nval wordCountMap = commentsDF\n      .flatMap(_.split(\" \"))\n      .map(w => (w, 1))\n      .countByKey()\n// Convert Map to Dataset\nval wordCountDF = sc.parallelize(wordCountMap.toSeq)\n                        .toDF(\"word\", \"count\")\n                        .sort(desc(\"count\"))\nwordCountDF.show(50)","user":"anonymous","dateUpdated":"2018-01-11T10:04:47+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.sql.functions.desc\nwordCountMap: scala.collection.Map[String,Long] = Map(zubac -> 1, klasicky -> 1, oba -> 1, fenomen -> 1, htm -> 1, malatin -> 1, 45 -> 1, vlhkost -> 1, chybajuci -> 1, formulacia -> 3, zobudit -> 2, vacsina -> 3, chybat -> 1, usmrtenou -> 1, ocenovat -> 1, vyborny -> 2, nenechat -> 1, najst -> 6, spravanie -> 4, teplice -> 1, vyskusat -> 2, teplaky -> 1, zdravit -> 4, dodatocny -> 2, predajny -> 33, huraa -> 1, e -> 4, vona -> 1, praca -> 2, trcat -> 1, setrit -> 1, zviera -> 1, vysoka -> 8, pavuk -> 1, nehadzat -> 2, deravy -> 1, nemislite -> 1, politika -> 2, nedostatok -> 1, poistka -> 1, evicka -> 1, macka -> 1, daky -> 2, babatko -> 1, inak -> 4, vcas -> 1, pocitit -> 1, suseda -> 2, hora -> 5, obalenie -> 2, svetovladcou -> 1, vzatych -> 1, vlacik -> 5, zlacniet -> 1, odstavovac -...\nwordCountDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [word: string, count: bigint]\n+---------+-----+\n|     word|count|\n+---------+-----+\n|      byt|  554|\n|     cena|  158|\n|       on|  122|\n|       ta|  106|\n|    vajce|  102|\n|       ja|   90|\n|     lidl|   85|\n|     kriz|   72|\n|  vajicko|   68|\n|      ani|   64|\n|    kupit|   63|\n|     este|   61|\n|      vas|   59|\n|      sty|   58|\n|    letak|   55|\n|slovensky|   51|\n|      ist|   50|\n|       vy|   50|\n|    nebyt|   50|\n|   vsetok|   49|\n|    nemat|   48|\n|     buda|   48|\n|       my|   44|\n|      tam|   42|\n|  dakovat|   42|\n|   boliet|   41|\n|        u|   40|\n|   clovek|   40|\n|        d|   40|\n|     taky|   38|\n|   chciet|   37|\n|       ci|   35|\n|      rad|   34|\n|      iny|   34|\n| predajny|   33|\n|    lidli|   33|\n|     lebo|   33|\n|     mama|   33|\n|     toto|   31|\n|    ktory|   31|\n|      dat|   30|\n|slovensko|   30|\n|      aky|   30|\n|     mata|   30|\n|       to|   29|\n|     moct|   29|\n|      nic|   29|\n|  kupovat|   28|\n|    nizky|   27|\n|     tato|   27|\n+---------+-----+\nonly showing top 50 rows\n\n"}]},"apps":[],"jobName":"paragraph_1515587108748_-248185658","id":"20180110-122508_30319047","dateCreated":"2018-01-10T12:25:08+0000","dateStarted":"2018-01-11T10:04:48+0000","dateFinished":"2018-01-11T10:04:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16505"},{"text":"import org.apache.spark.sql.Encoders\n// Sum of all word counts\nval sumWordsDF = wordCountDF.agg(sum(\"count\"))\nsumWordsDF.show()\nval sumWordsDouble = sumWordsDF.as(Encoders.DOUBLE).collect()\nprintln(\"Number of words \" + sumWordsDouble(0))","user":"anonymous","dateUpdated":"2018-01-11T10:04:47+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.sql.Encoders\n\nsumWordsDF: org.apache.spark.sql.DataFrame = [sum(count): bigint]\n+----------+\n|sum(count)|\n+----------+\n|      9710|\n+----------+\n\n\nsumWordsDouble: Array[Double] = Array(9710.0)\nNumber of words 9710.0\n"}]},"apps":[],"jobName":"paragraph_1515587307404_195720983","id":"20180110-122827_508342449","dateCreated":"2018-01-10T12:28:27+0000","dateStarted":"2018-01-11T10:04:49+0000","dateFinished":"2018-01-11T10:04:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16506"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1515678562390_231251995","id":"20180111-134922_791785093","dateCreated":"2018-01-11T13:49:22+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:16531"}],"name":"2018W02.text-analysis-wordcount","id":"2D56NAPT4","angularObjects":{},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}